<!DOCTYPE html>
<html lang="zh-cmn-Hans">

<head>
    <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="HandheldFriendly" content="true">
    <meta charset="UTF-8">
    <meta name="keywords" content="生物医学统计基础">
    <meta name="description" content="6 两个、多个变量之间的关系 - 生物医学统计基础">
    <meta name="author" content="MingXiao">
    <title>6 两个、多个变量之间的关系</title>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="/assets/css/global.css">
    <link rel="stylesheet" href="/assets/css/pace-theme-flash.css">
    <link rel="stylesheet" href="/assets/css/d-audio.css">
    <link rel="stylesheet" href="/assets/css/article-detail.css">
    <link rel="stylesheet" href="/assets/css/code.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/vditor.css">
    <link rel="stylesheet" href="/assets/css/markdown.css">
    <link rel="shortcut icon" href="/images/blog-logo.png">
    <style>
        .lazy-image {
            background: url('/images/loading.gif') no-repeat center;
            background-size: 26% 35%;
            height: 100%;
            width: 100%;
        }

        .markdown-body {
            box-sizing: border-box;
            min-width: 200px;
            max-width: 980px;
            margin: 0 auto;
            padding: 10px;
        }

        @media (max-width: 767px) {
            .markdown-body {
                padding: 15px;
            }

            .markdown-body h1 {
                font-size: 1.35em;
            }

        }

        .codehilite {
            border-radius: 10px;
        }

        .article-content img {
            max-width: 100%;
        }

        #outerdiv {
            width: 100%;
            height: 100%;
            position: fixed;
            top: 0;
            left: 0;
            background: rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 200;
        }
    </style>
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
</head>
<body>
    <script src="/assets/js/include.js"></script>
    <div data-include="/includes/nav.html"></div>
        <div class="toc">
            <ul>
                <li>6 两个、多个变量之间的关系
                    <ul>
                            <li><a href="#7.1">6.1 相关性分析</a></li>
                            <li><a href="#7.2">6.2 简单线性回归分析</a></li>
                            <li><a href="#7.3">6.3 多元线性回归模型(MLR)</a></li>
                    </ul>
                </li>
            </ul>
        </div>

    <!--主体-->
    <section class="main">
        <div class="left-box">
            <div id="outerdiv">
                <div id="innerdiv" style="position:absolute;"><img alt id="bigimg"
                        style="box-shadow: 0 0 10px rgba(0,0,0,0.38)" src="" /></div>
            </div>
            <!--文章内容-->
            <div class="article-container">
                <div class="article-content markdown-body">
                    <h1 style="margin: 10px 0">6 两个、多个变量之间的关系</h1>
                    <div class="article-cate">
                        <a href="/Category/LearningHomepage.html">学习笔记</a>
                    </div>
                    <div class="writer-info">
                        <span style="margin: 5px 0;">作者: </span>
                        <span id="writer">MingXiao</span>
                    </div>
                    <div class="typora-export os-windows">
<a name="7.1" class="md-header-anchor" id="7.1"></a>
<h3>6.1 相关性分析</h3>
<h4>6.1.1 协方差</h4>
<p>某个样本有两个变量，记为\(X,Y\)，其观测值记为\(x_i,y_i\)，则\(x,y\)的协方差为<br>\(\text{cov}(x,y)=\frac{\sum_{i}(x_i-\overline{x})(y_i-\overline{y})}{n-1}\)，n-1是无偏估计<br>注意在概统中曾经提过的协方差\(\text{cov}(X,Y)=E(\sum_i(X_i-\overline{X})(Y_i-\overline{Y}))\)是总体的，所以不除\(n-1\)</p>
<details>
    <summary>python代码</summary>
    data是一个dataFrame<br>
    data[["obj1","obj2"]].cov()
</details>

<p>很显然\(cov(2x,2y)=4cov(x,y)\)，即协方差受量纲的影响，为了解决这个问题，使用相关系数</p>
<h4>6.1.2 相关系数</h4>
<p><strong>以下三个相关系数，只需且只能算一个</strong></p>
<h5>6.1.2.1 Pearson&#39;s linear(Pearson 相关系数)</h5>
<p>\(r_{x,y}=\frac{cov(x,y)}{s_x\cdot s_y}=\frac{\sum_i(x_i-\overline{x})(y_i-\overline{y})}{\sqrt{\sum_i(x_i-\overline{x})^2\sum_i(y_i-\overline{y})^2}}\)<br>其中\(\sigma\)是各自的样本方差，除以样本方差后变为无量纲的量</p>
<p>经验上将\(|r|\)分为以下三类</p>
<ol>
<li>0.1~0.3, Small</li>
<li>0.3~0.5, Medium</li>
<li>\(>\)0.5, large</li>
</ol>
<p>r对outlier很敏感，r是数据分布<strong>是否线性</strong>的判断；r=0仅能说明线性关系弱，不是没有关系</p>
<details>
    <summary>python代码</summary>
    r, p = stats.pearsonr(data.obj1, data.obj2)<br>
    返回两个量，r是相关系数，p是对相关系数做r=0的NHST的p<br>
    data.corr(method="pearson")<br>
    对整个dF求相关系数
</details>

<h5>6.1.2.2 Spearman&#39;s \(\rho\)</h5>
<p>使用情况：</p>
<ol>
<li>X,Y不是数值，而是一个排序的变量，<strong>or</strong></li>
<li>X,Y没有明显的线性关系</li>
</ol>
<p>首先将原始的\((x_i,y_i)\)排序，用排序后的顺序作为新的值，带入\(r_{x,y}\)的公式计算<br>用于评估单调关系</p>
<p><font color=red>例：X[5,2,8,1,4];Y[10,4,12,3,8]</font><br>首先排序，得到新的:R[3,2,5,1,4];S[4,2,5,1,3]，对应的\((r_i,s_i)\)不变<br>如果有相同的，就并列，如R[1,2,2,4,5]<br>而平均值就是排序后正常计算的平均值，用新的数组带入上述公式</p>
<p>def 	\(d_i=R_i-S_i\)，则有<br>\(\rho=1-\frac{6\sum_id_i^2}{N(N^2-1)}\)，其中N是样本观测量，上例中N=5，和上式计算结果一致</p>
<details>	
    <summary>python代码</summary>
    r, p = spearmanr(data.obj1, data.obj2)<br>
    返回两个量，r是相关系数，p是对相关系数做r=0的NHST的p<br>
    data.corr(method="spearman")<br>
    对整个dF求相关系数
</details>

<h5>6.1.2.3 Kendall&#39;s \(\tau\)</h5>
<p>使用情况：</p>
<ol>
<li>X,Y不是数值，而是一个排序的变量，<strong>or</strong></li>
<li>X,Y没有明显的线性关系</li>
</ol>
<img src="/Category/Learning/Pictures/BmeStats_13.png">

<details>
    <summary>python代码</summary>
	r, p = kendalltau(data.obj1, data.obj2)<br>
    返回两个量，r是相关系数，p是对相关系数做r=0的NHST的p<br>
</details>

<h4>6.1.3 相关系数的置信区间估计，NHST</h4>
<p>用样本观测值得到的样本相关系数，可以推测总体相关系数的区间<br>实际上为了得到总体的相关系数也只能这么做<br>使用Fisher-z变换修正偏度，得到以下表格</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Fisher-z</th>
<th align="center">CI of z</th>
<th align="center">CI we need</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Pearson’s r</td>
<td align="center">\(z_r=\frac{1}{2}\ln{\frac{1+r}{1-r}}\)</td>
<td align="center">\(z_r\pm z_{\alpha/2}\sqrt{\frac{1}{n-3}}\)</td>
<td align="center">\(r_L=\frac{e^{2z_{L}}-1}{e^{2z_{L}}+1},r_U=\frac{e^{2z_{U}}-1}{e^{2z_{U}}+1}\)</td>
</tr>
<tr>
<td align="center">Spearman&#39;s \(\rho\)</td>
<td align="center">\(z_{\rho}=\frac{1}{2}\ln{\frac{1+\rho}{1-\rho}}\)</td>
<td align="center">\(z_\rho\pm z_{\alpha/2}\sqrt{\frac{1+\rho^2/2}{n-3}}\)</td>
<td align="center">\(\rho_L=\frac{e^{2z_{L}}-1}{e^{2z_{L}}+1},\rho_U=\frac{e^{2z_{U}}-1}{e^{2z_{U}}+1}\)</td>
</tr>
<tr>
<td align="center">Kendall&#39;s \(\tau\)</td>
<td align="center">\(z_{\tau}=\frac{1}{2}\ln{\frac{1+\tau}{1-\tau}}\)</td>
<td align="center">\(z_\tau\pm z_{\alpha/2}\sqrt{\frac{0.437}{n-4}}\)</td>
<td align="center">\(\tau_L=\frac{e^{2z_{L}}-1}{e^{2z_{L}}+1},\tau_U=\frac{e^{2z_{U}}-1}{e^{2z_{U}}+1}\)</td>
</tr>
</tbody></table>
<p>注意，求得的置信区间是<strong>非对称</strong>的</p>
<h4>6.1.4 Pearson&#39;s r相关分析假设条件</h4>
<ol>
<li>两个连续变量（或近似于连续）</li>
<li>描述<strong>线性</strong>关系</li>
<li>没有异常值outlier</li>
<li><strong>相关性不等于因果性</strong>；p值不反应总体的相关性</li>
<li><font color=red>观测值相互独立</font></li>
</ol>
<h4>6.1.5 APA报告</h4>
<p>Pearson相关分析表明，两个变量之间存在很强/中等/弱/没有线性相关性（r(N)=.30,p&lt;.001,95%CI=[0.15,0.35]）<br>N是样本观测量</p>
<a name="7.2" class="md-header-anchor" id="7.2"></a>
<h3>6.2 简单线性回归分析</h3>
<p>根据样本值，建立一阶线性模型\(Y=\beta_0+\beta_1X\)，要求XY都是连续变量</p>
<p>实际上，根据有限的样本值得到的样本观测模型为\(y_i=b_0+b_1x_i+\epsilon_i\)，其中\(\epsilon_i\)为第i组观测值的误差，\((x_i,b_0+b_ix_i)\)为第i组回归值/预测值<br><font color=red>注意，每一组样本值都应该<strong>独立</strong></font></p>
<p><font color=red>例：建立物理成绩和数学成绩的简单回归模型，下面的计算结果都是正确的，问哪个说法是正确的</font></p>
<ol>
<li>某同学，数学80分的，建议推断其物理成绩是80分</li>
<li><font color=red>数学成绩为80分的同学，物理平均分为82分</font></li>
<li>可以通过提高数学成绩，来提高物理成绩</li>
<li>一组学生经过训练，数学成绩提高5分，则平均物理成绩提高约4.5分</li>
<li><font color=red>数学成绩平均为90分的学生比数学成绩平均80分的学生，物理成绩平均高9分</font></li>
</ol>
<p>正确的是标红的；不能推断单个；不能推断一个样本的变化</p>
<h4>6.2.1 估计样本回归模型</h4>
<p>为了得到\(y=b_0+b_1x\)，需要进行线性拟合，这里使用最小二乘法(Ordinary Least Square)<br>预测值\(\hat{y_i}=b_0+b_1x_i\)，误差\(\epsilon_i=y_i-\hat{y_i}=(y_i-b_0-b_ix_i)\)<br>def 	样本整体预测误差(sum of squared errors)\(\text{SSE}=\sum_i(y_i-\hat{y_i})^2\)<br>\(b_0,b_1\)要使得SSE最小，则\(\frac{\part\text{SSE}}{\part b_0}=\frac{\part\text{SSE}}{\part b_1}=0\)<br>\(\Rightarrow b_0=\bar{y}-b_1\bar{x},b_1=\frac{n\sum_i{x_iy_i}-\sum_ix_i\sum_iy_i}{n\sum_ix_i^2-(\sum_ix_i)^2}=\frac{\text{COV(x,y)}}{\text{D}(x)}\)<br>注意\(b_i\)的第二种算法使用的是计算总体的方法，即\(/n\)而非\(/(n-1)\)，当然用样本的计算结果是一致的</p>
<p>得到样本回归模型\(y=b_0+b_1x\)，注意这只能表示观测对象和自变量的关系，<strong>对观测值不适用</strong></p>
<h4>6.2.2 总体模型</h4>
<p>由样本推总体无非是CI和NHST</p>
<img src="/Category/Learning/Pictures/BmeStats_15.png">

<p>得到\(\beta_0和\beta_1\)的CI，注意t分布的自由度是n-2，因为使用样本估计了方差（n-1-1）</p>
<details>
    <summary>python代码</summary>
    LR = stats.linregress(data.obj1,data.obj2)<br>
    在残差正态性下，依次输出<br>
    slope，斜率，即b1<br>
    intercept，截距，即b0<br>
    rvalue，两个变量的r相关系数<br>
    pvalue，b1=0做NHST得到的p<br>
    stderr，b1的标准误差，不是标准差<br>
    intercept_stderr，b0的标准误差<br>
</details>

<p>为了使X=0时的Y有意义，即为了x=0时截距有意义，一般会将X做随机变量中心化，此时截距的意义就是X为平均值时的Y值；做随机变量标准化是为了解决量纲的影响</p>
<h4>6.2.3 模型误差估计</h4>
<h5>6.2.3.1 均值CI(CIB)</h5>
<p>每个观测值x处，对应的y（多个）的均值\(\hat{y}\)的CI，有\(\hat{y}_{ci}=\hat{y}\pm t_{\alpha/2}(n-2)\cdot \sqrt{MSE}\cdot \sqrt{\frac{1}{n}+\frac{(x-\bar{x})^2}{\sum_i(x_i-\bar{x})^2}}\)<br>其中\(MSE=\frac{\sum(y_i-\hat{y_i})^2}{n-2}\)</p>
<p>注意这是\(\hat{y}\)在x处的CI</p>
<h5>6.2.3.2 观测值CI(PIB)</h5>
<p>每个观测值x处，对应的观测值y的CI，有\({y_{pi}}=\hat{y}\pm t_{\alpha/2}(n-2)\cdot \sqrt{MSE}\cdot \sqrt{1+\frac{1}{n}+\frac{(x-\bar{x})^2}{\sum_i(x_i-\bar{x})^2}}\)<br>MSE见上</p>
<details>
    <summary>python代码</summary>
    import statsmodels.formula.api as smf<br>
	model = smf.ols("Height~Weight", data=data)<br>
	results = model.fit()<br>
    其中results.summary()函数会给出报告
</details>
<img src="/Category/Learning/Pictures/BmeStats_17.png" 	width="700">

<p>当共线性很强（残差线性相关）时，模型不能用来解释变量之间的关系（拟合地不好），但是仍然能用于预测数值<br>NHST的零假设是bi=0；当残差的方差过大时，模型不能用来预测，但是解释的效果可以</p>
<h4>6.2.4 一阶线性回归模型的假设</h4>
<ol>
<li>X，Y都是连续变量</li>
<li>Y随X线性变化</li>
<li>残差正态性，\(\epsilon \sim N(0,\sigma^2)\)</li>
<li>所有数据i.i.d.</li>
<li>自变量在同一个level上</li>
</ol>
<h4>6.2.5方差分析</h4>
<p>定义\(SST=\sum_i(y_i-\bar{y})^2=\sum_i(y_i-\hat{y_i}+\hat{y_i}-\bar{y})^2=\sum_i(y_i-\hat{y_i})^2+\sum_i(\hat{y_i}-\bar{y})^2+2\sum_i(y_i-\hat{y_i})(\hat{y_i}-\bar{y})\)<br>当满足OLS时，第三项=0，定义\(SSR=\sum_i(\hat{y_i}-\bar{y})^2\)，\(SSE=\sum_i(y_i-\hat{y_i})^2\)<br>故\(SST=SSR+SSE\)，SSR是自变量能解释的SS，SSE是自变量不能解释的SS(Error)<br>定义\(R^2=\frac{SSR}{SST}=1-\frac{SSE}{SST}\)<br>代入定义式有\(R^2=\frac{\sum_i(\hat{y_i}-\bar{y})^2}{\sum_i(y_i-\bar{y})^2}\)，又\(\hat{y_i}=b_1x_i+b_0\)，最终得到\(r(x,y)=\pm\sqrt{R^2}\)<br>又有\(r(x,y)=\frac{\text{COV}(x,y)}{\sqrt{\text{D}(x)\text{D}(y)}},b_1=\frac{\text{COV}(x,y)}{\text{D}(x)}\)<br>\(\therefore b_1=r(x,y)\cdot\frac{\sqrt{\text{D}(y)}}{\sqrt{\text{D}(x)}}\)<br>当然用样本方差也行，因为n都除掉了，实际上r使用样本的量来计算得到的结果也是一致的</p>
<p>故可以根据两个变量的均值，方差，R2来估计线性回归模型<br><strong>R2越大，模型预测越准确</strong></p>
<a name="7.3" class="md-header-anchor" id="7.3"></a>
<h3>6.3 多元线性回归模型(MLR)</h3>
<p>连续的观测量与多个因变量的关联：\(SBP_i=b_0+b_1x_{1i}+b_2x_{2i}+\ldots+\epsilon_i\)，线性指的是系数（bi）是线性的，而非自变量，如\(y=b_0+b_1x+b_1x^2\)也是线性回归模型</p>
<p>而一般线性回归模型（GLM）通常还有一个类别变量</p>
<p>同样的，MLR也是用最小二乘法估计</p>
<p><img src="/Category/Learning/Pictures/BmeStats_16.png" 	width="500"></p>
<p>这也导致outlier的干扰很大</p>
<details>
    <summary>python代码</summary>
    model = smf.ols("Height~Weight+GymTime", data=data)<br>在这里用+连接自变量
	results = model.fit()<br>
	print(results.summary())<br>
    报告格式和一阶模型一致
</details>
#### 6.3.1 MLR系数解释

<ul>
<li>无交互作用，\(y=b_0+b_1x_1+\ldots+b_nx_n\)</li>
</ul>
<p>在解释系数时，不能说单个样本的变化，而是总体的差异</p>
<p>报告给出的t检验的\(H_0:b_i=0\)，即因变量和这个因素无关</p>
<ul>
<li>存在交互作用，\(y=b_0+b_1x_1+b_2x_2+b_3x_1x_2\)</li>
</ul>
<p>\(b_1,b_2\)的涵义变化为<strong>其他自变量为0时</strong>，该变量的影响<br>\(b_3\)可以这么看：\(y=b_0+b_1x_1+(b_2+b_3x_1)x_2\)<br>即x2的系数与x1有关，在不同的x1水平下，x2对y的作用存在变化，<strong>\(x_1,x_2\)存在交互作用</strong><br>b3可以认为是两组差异的差异</p>
<img src="/Category/Learning/Pictures/BmeStats_18.png" width="300">

<p>如要说明某种新药的显著性，也是用上面的方法<br>即枢轴量<strong>不使用\(f(1,1)-f(1,0)\)，而使用\(b_3=[f(1,1)-f(0,1)]-[f(1,0)-f(0,0)]\)，即差异的差异</strong><br>这也说明，如果两条线不平行，那么说明可能存在交互作用</p>
<h4>6.3.2 模型评价</h4>
<h5>6.3.2.1 残差特性</h5>
<p>类似于6.2.3.2</p>
<p>好的模型，残差特性有</p>
<ol>
<li><p>正态分布性：</p>
<ul>
<li>Jarque-Bera检验的零假设是数据服从正态分布，备择假设是数据不服从正态分布<br>它基于样本的skewness和kurtosis来进行检验</li>
</ul>
</li>
<li><p>自相关性弱：残差的值是否独立，是否有\(\epsilon_{i}=f(\epsilon_{i-1})\)，不是一般意义上的两个变量相关</p>
<ul>
<li>当Durbin-Watson统计量接近2时(1.5~2.5)，表示残差不存在自相关性（即残差之间相互独立）</li>
<li>当Durbin-Watson统计量接近0或4时，表示存在正向或负向的自相关性</li>
</ul>
</li>
<li><p>共线性弱：即残差之间线性无关；当残差共线性强时，说明模型漏了某些解释变量</p>
</li>
<li><p>方差齐性：数据不是喇叭口状的，在x不同水平下残差的范围比较一致</p>
</li>
</ol>
<img src="/Category/Learning/Pictures/BmeStats_20.png" width="300">

<p>好的残差分布，已经归一化</p>
<h5>6.3.2.2 总体评价</h5>
<p>包括\(R^2\)，Adjusted \(R^2\)，AIC，BIC，F-value，P-value</p>
<p>\(R^2=\frac{SSR}{SST}=1-\frac{SSE}{SST},R^2_{adj}=1-\frac{(1-R^2)(n-1)}{n-p-1}\)<br>其中n为样本大小，p为自变量个数<br>当自变量数量变多，Adj R2会减小，模型存在过拟合风险</p>
<p><strong>模型总体的显著性为F-value</strong></p>
<img src="/Category/Learning/Pictures/BmeStats_19.png" width="500">

<p>R2是服从F分布的，自由度不用管，<strong>F-value是优先于T-value</strong>的，当模型的F-value不足时，t的P值再显著，也不太有效，t的P值是H0：bi=0的NHST检验值</p>
<p><strong>AIC与BIC</strong></p>
<p>AIC从预测角度，表明模型对<strong>未知数据的预测程度</strong>，<strong>AIC越小</strong>，意味着模型更简洁和精确</p>
<p>BIC从拟合角度，表明模型对<strong>当前数据的拟合程度</strong>，<strong>BIC越小</strong>，意味着模型更更简洁</p>
<h4>6.3.3 模型汇报</h4>
<p>最好用表格</p>
<p>文字的APA：<br>Social support significantly predicted depression scores（bi= -.34, t(225) = 6.53, p&lt; .001）</p>
<p>也要汇报R2，F，p<br>Social support also explained a significant proportion of variance in depression scores（R2 = .12, F(1, 225) = 42.64,p&lt; .001）</p>
<p>如果模型有显著的交互作用，主效应的解释要谨慎，因为主效应<strong>可能是交互作用引起的</strong></p>
<p>模型描述的变量间的关联性，<strong>避免把结果解释成因果性</strong></p>
<p>大的R2值不一定好的模型，同样小的R2不一定是差的模型</p>
<h4>6.3.4 实际使用的优化方法</h4>
<p><strong>数据可视化</strong>：pairplot/scatterplot/jointplot, 发现存在相关性的变量（predictors)</p>
<p><strong>物理原理</strong>/<strong>实际问题</strong>：根据实际问题选取存在相关性的变量</p>
<p><strong>数据驱动的模型选择（比较常用，但需要谨慎）</strong></p>
<ul>
<li>Stepwise 选择： 增、减变量，观察AIC/BIC，\(R_{adj}^2\)值的变化，朝增加\(R_{adj}^2\)方向, AIC/BIC减小的方向选择</li>
</ul>
<p><strong>模型评价</strong>：看残差特征</p>

                    </div>    
                </div>
            </div>                                                                                                                                              
            <br>
            <br>
            <h2 id="__comments">Comments</h2>
                  <!-- Giscus comments -->
                    <script src="https://giscus.app/client.js"
                            data-repo="MingX1ao/MingX1ao.github.io"
                            data-repo-id="R_kgDOL_cJHA"
                            data-category="General"
                            data-category-id="DIC_kwDOL_cJHM4CgVLq"
                            data-mapping="pathname"
                            data-strict="0"
                            data-reactions-enabled="1"
                            data-emit-metadata="0"
                            data-input-position="bottom"
                            data-theme="light"
                            data-lang="zh-CN"
                            data-loading="lazy"
                            crossorigin="anonymous"
                            async>
                    </script>
        </div>
    </section>
    <!--尾部-->
    <div data-include="/includes/footer.html"></div>
    <script>
        document.addEventListener('includesReady', function() {
            const lazyImage = new LazyImage('.lazy-image');
        });
    </script>
</body>

</html>
